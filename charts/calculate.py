# plots.py
import io, base64
import pandas as pd
import numpy as np
import matplotlib
import matplotlib.dates as mdates  # ç¡®ä¿æœ‰è¿™è¡Œ
matplotlib.use("Agg")
from matplotlib import pyplot as plt
from typing import Optional
from typing import Iterable, List, Tuple, Optional, Dict, Any, Union

def compute_datetime_upper_envelope(
    x,
    y,
    bins: int = 300,
    q: float = 0.97,
    roll: int = 5,
    min_bins: int = 10,
):
    """
    Build a time-based upper envelope for (x, y) where x are datetimes (any tz) and y are numeric.
    Returns both detailed arrays and a highlight_df (x_mid, y_envelope) for plotting or export.
    """
    # --- 1) Clean & normalize types ---
    x = pd.to_datetime(x, errors="coerce")
    x = pd.DatetimeIndex(x)
    if x.tz is not None:
        x = x.tz_convert("UTC").tz_localize(None)

    y = np.asarray(pd.to_numeric(y, errors="coerce"))

    # --- 2) Filter valid rows ---
    m = (~x.isna()) & np.isfinite(y)
    x = x[m]
    y = y[m]
    if x.size == 0:
        raise ValueError("No valid data after cleaning.")

    # --- 3) Convert datetime â†’ int64 ns ---
    xn = x.asi8

    # --- 4) Sort ---
    idx = np.argsort(xn)
    xs, ys = xn[idx], y[idx]
    xs_time = pd.to_datetime(xs)

    # --- 5) Bin + envelope ---
    B = int(min(bins, max(min_bins, xs.size // 5)))
    edges = np.linspace(xs.min(), xs.max(), B + 1)
    which = np.clip(np.digitize(xs, edges, right=True) - 1, 0, B - 1)

    yq = np.full(B, np.nan)
    for i in range(B):
        yi = ys[which == i]
        if yi.size:
            yq[i] = np.quantile(yi, q)

    x_mid = pd.to_datetime(((edges[:-1] + edges[1:]) / 2).astype("int64"), unit="ns")
    line = pd.Series(yq).rolling(roll, center=True, min_periods=1).median().to_numpy()
    mask = np.isfinite(line)

    # --- 6) Build highlight_df ---
    highlight_df = pd.DataFrame({
        "x_mid": x_mid[mask],
        "y_envelope": line[mask]
    })

    return {
        "xs_time": xs_time,    # cleaned and sorted timestamps
        "ys": ys,              # numeric series
        "x_mid": x_mid,        # bin midpoints
        "y_env": line,         # smoothed envelope
        "mask": mask,          # finite mask
        "highlight_df": highlight_df  # DataFrame ready for plotting/export
    }

def compute_adjR2(n, sx, sy, sxx, sxy, syy, p=2, eps=1e-12):
    """
    ä½¿ç”¨ç´¯ç§¯é‡ç›´æ¥è®¡ç®—ä¸€é˜¶çº¿æ€§å›å½’çš„ Adjusted R^2.

    å‚æ•°
    ----
    n   : æ ·æœ¬æ•°
    sx  : sum(x)
    sy  : sum(y)
    sxx : sum(x^2)
    sxy : sum(x*y)
    syy : sum(y^2)
    p   : æ¨¡å‹å‚æ•°ä¸ªæ•° (ä¸€å…ƒçº¿æ€§å›å½’é€šå¸¸ä¸º 2: Î²0, Î²1)
    eps : æ•°å€¼ç¨³å®šç”¨çš„æå°é‡
    """

    # æ ·æœ¬å¤ªå°‘ï¼Œæ— æ³•æ‹Ÿåˆ
    if n <= p:
        return 0.0

    # è®¡ç®—å›å½’ç³»æ•° Î²1, Î²0
    denom = n * sxx - sx * sx
    if abs(denom) < eps:
        # x æ²¡æœ‰å˜åŒ–ï¼Œæ— æ³•å›å½’ï¼Œè¿”å› 0
        return 0.0

    beta1 = (n * sxy - sx * sy) / denom
    beta0 = (sy - beta1 * sx) / n

    # SSE: Residual Sum of Squares
    # åˆ©ç”¨é—­å¼ï¼šSSE = syy - Î²0 * sy - Î²1 * sxy
    SSE = syy - beta0 * sy - beta1 * sxy

    # SST: Total Sum of Squares
    # SST = Î£(y - È³)^2 = syy - sy^2 / n
    SST = syy - (sy * sy) / n

    if SST <= eps:
        # y åŸºæœ¬ä¸å˜ï¼ŒRÂ² æ²¡æ„ä¹‰ï¼Œè§†ä¸º 0
        return 0.0

    # RÂ²
    R2 = 1.0 - SSE / SST

    # Adjusted RÂ²
    # adjR2 = 1 - (1 - R2) * (n - 1) / (n - p)
    denom_adj = (n - p)
    if denom_adj <= 0:
        return R2

    adjR2 = 1.0 - (1.0 - R2) * (n - 1) / denom_adj

    # é˜²æ­¢æ•°å€¼è¯¯å·®è¶…ç•Œï¼Œå¤¹åˆ° [-1, 1]
    if adjR2 > 1.0:
        adjR2 = 1.0
    elif adjR2 < -1.0:
        adjR2 = -1.0

    return float(adjR2)


def compute_MSE(n, sx, sy, sxx, sxy, syy, p=2, eps=1e-12):
    """
    ä½¿ç”¨ç´¯ç§¯é‡ç›´æ¥è®¡ç®—ä¸€é˜¶å›å½’çš„ MSE (Mean Squared Error)
    n   = æ ·æœ¬æ•°
    sx  = sum(x)
    sy  = sum(y)
    sxx = sum(x^2)
    sxy = sum(x*y)
    syy = sum(y^2)
    p   = å‚æ•°æ•°é‡(çº¿æ€§å›å½’ä¸º2: Î²0, Î²1)
    """

    if n < p:
        return float("inf")  # ä¸è¶³ä»¥æ‹Ÿåˆï¼Œè§†ä¸ºæå·®

    denom = (n * sxx - sx * sx)

    if abs(denom) < eps:  # é¿å…é™¤0
        return float("inf")

    # å›å½’ç³»æ•°
    beta1 = (n * sxy - sx * sy) / denom
    beta0 = (sy - beta1 * sx) / n

    # æ®‹å·®å¹³æ–¹å’Œ SSE
    SSE = syy - beta0 * sy - beta1 * sxy

    # **æœ€ç»ˆ MSE**
    return max(SSE / n, 0)  # é˜²æ•°å€¼è´Ÿè¯¯å·®


def split_by_metric(points, drop_thre=0.01, w=2, min_len=8,
                    rel_drop=False, rel_drop_thre=0.02, k=1,
                    metric='mse', eps=1e-12):
    """
    é€šç”¨åˆ†æ®µï¼šå¯ç”¨ AdjRÂ² æˆ– MSE ä½œä¸ºç›‘æ§æŒ‡æ ‡ã€‚
    points: list of (x, y) sorted by x
    metric: 'adjr2' æˆ– 'mse'
    """

    # ä½ å·²æœ‰çš„ä¸¤ä¸ªæŒ‡æ ‡å‡½æ•°ï¼ˆè¯·ç¡®ä¿è¿™ä¸¤ä¸ªå‡½æ•°å·²å®šä¹‰åœ¨åŒä¸€ä½œç”¨åŸŸä¸­ï¼‰
    # compute_adjR2(n, sx, sy, sxx, sxy, syy, p, eps=1e-12) -> float
    # compute_MSE(n, sx, sy, sxx, sxy, syy, p, eps=1e-12)   -> float

    if metric.lower() == 'adjr2':
        metric_fn = lambda n, sx, sy, sxx, sxy, syy, p: compute_adjR2(n, sx, sy, sxx, sxy, syy, p, eps)
        better_is_higher = True
        small = 1e-6  # ç”¨äºç›¸å¯¹æ¯”å€¼çš„åˆ†æ¯ä¿æŠ¤

    elif metric.lower() == 'mse':
        metric_fn = lambda n, sx, sy, sxx, sxy, syy, p: compute_MSE(n, sx, sy, sxx, sxy, syy, p, eps)
        better_is_higher = False
        small = 1e-12
    else:
        raise ValueError("metric must be 'adjr2' or 'mse'")

    p = k + 1

    segments = []

    breakpoints = []

    def reset_state():
        # è¿”å›ï¼šn, sx, sy, sxx, sxy, syy, last_metric, bad_streak
        return 0, 0.0, 0.0, 0.0, 0.0, 0.0, None, 0
    
    # åˆå§‹åŒ–
    start = 0
    n = sx = sy = sxx = sxy = syy = 0
    last_metric = None
    bad_streak = 0

    # ä¸ºäº†åœ¨åˆ‡åˆ†æ—¶è®°å½•å½“æ—¶çš„æŒ‡æ ‡å€¼ï¼Œæˆ‘ä»¬åŒæ—¶è·Ÿè¸ªâ€œä¸Šä¸€æ¬¡ç”¨äºæ¯”è¾ƒçš„æŒ‡æ ‡å€¼â€
    metric_at_prev = None
    for t, (x, y) in enumerate(points):
        # æ›´æ–°ç´¯è®¡é‡
        n += 1
        sx += x
        sy += y
        sxx += x * x
        syy += y * y
        sxy += x * y

        # èµ·å§‹é•¿åº¦ä¸è¶³åˆ™è·³è¿‡
        if n < max(min_len, p + 1):
            continue

        # å½“å‰åŒºæ®µçš„æŒ‡æ ‡
        cur_metric = metric_fn(n, sx, sy, sxx, sxy, syy, p)
 
        # æ£€æŸ¥æ˜¯å¦â€œå˜åâ€
        bad = False
        if last_metric is not None:
            delta = cur_metric - last_metric
            if better_is_higher:
                # AdjRÂ²ï¼šä¸‹é™ä¸ºåï¼ˆdelta < -é˜ˆå€¼ï¼‰
                if delta < -drop_thre:
                    bad = True
                elif rel_drop:
                    denom = max(abs(last_metric), small)
                    if (delta / denom) < -rel_drop_thre:
                        bad = True
            else:
                # MSEï¼šä¸Šå‡ä¸ºåï¼ˆdelta > +é˜ˆå€¼ï¼‰
                if delta > +drop_thre:
                    bad = True
                elif rel_drop:
                    denom = max(abs(last_metric), small)
                    if (delta / denom) > +rel_drop_thre:
                        bad = True

        # é€’æ¨åè®¡æ•°
        if bad:
            bad_streak += 1
        else:
            bad_streak = 0


        # æ›´æ–°â€œä¸Šä¸€æ—¶åˆ»çš„æŒ‡æ ‡â€
        last_metric = cur_metric
        metric_at_prev = cur_metric  # è®°å½•æœ€è¿‘ä¸€æ¬¡è®¡ç®—å€¼

        # è¿ç»­åæ»¡ w æ¬¡ â†’ åˆ‡åˆ†
        if bad_streak >= w:
            cut = t - w  # å›çœ‹çª—å£çš„èµ·ç‚¹ä½œä¸ºåˆ‡ç‚¹
            left_len = cut - start + 1

            if left_len >= max(min_len, p + 1):
                # è®°å½•å·¦æ®µï¼ˆä¸ºäº†æ›´ç¨³å¦¥ï¼Œå¯åœ¨ cut ä½ç½®é‡ç®—ä¸€æ¬¡æŒ‡æ ‡ï¼Œä½†è¿™é‡Œæ²¿ç”¨æœ€è¿‘å€¼ï¼‰
                segments.append({
                    "start": start,
                    "end": cut,
                    "metric": metric,
                    "value": last_metric
                })
                breakpoints.append(cut)

                # é‡ç½®ä» cut+1 åˆ°å½“å‰ t çš„ç´¯ç§¯
                start = cut + 1
                n, sx, sy, sxx, sxy, syy, last_metric, bad_streak = reset_state()
                # æŠŠå³ä¾§æ®‹ä½™ç‚¹é‡æ–°ç´¯ç§¯èµ·æ¥ï¼ˆå« t-w+1...tï¼‰
                for u in range(start, t + 1):
                    x_u, y_u = points[u]
                    n += 1
                    sx += x_u
                    sy += y_u
                    sxx += x_u * x_u
                    syy += y_u * y_u
                    sxy += x_u * y_u
                # é‡ç½®åï¼Œlast_metric ç½®ç©ºï¼Œè®©ä¸‹ä¸€è½®é‡æ–°å»ºç«‹åŸºçº¿
                last_metric = None
                metric_at_prev = None

    # æ”¶å°¾æ®µ

    segments.append({
        "start": start,
        "end": len(points) - 1,
        "metric": metric,
        "value": metric_at_prev
    })
    
    return segments, breakpoints

def plot_accumulative_complexity(df: pd.DataFrame, value_col: str, title="Accumulative Complexity", freq="W"):
    """
    Build a cumulative-sum chart over time for a numeric column.
    If no real date column exists, uses a synthetic timeline.

    Parameters
    ----------
    df : pd.DataFrame
        Input data.
    value_col : str
        Column containing complexity or numeric values.
    title : str
        Plot title.
    freq : str
        Frequency for resampling ('D', 'W', or 'M').

    Returns
    -------
    b64 : str
        Base64-encoded PNG chart.
    """

    # --- Generate synthetic timeline if no explicit date col ---
    # --- Generate REAL timeline instead of fake one ---
    df = df.dropna(subset=[value_col]).copy()
    if "x_mid" in df.columns:
        df["x_mid"] = pd.to_datetime(df["x_mid"], errors="coerce")
        df = df.dropna(subset=["x_mid"])
        df = df.sort_values("x_mid")
        time_col = "x_mid"  # â† å…³é”®ï¼šç”¨çœŸå®æ—¶é—´
    else:
        # âš ï¸ fallbackï¼šæ— æ—¥æœŸæ‰é€ å‡
        start = pd.Timestamp("2021-01-01")
        end   = pd.Timestamp("2024-12-31")
        df["_fake_date"] = pd.date_range(start, end, periods=len(df))
        time_col = "_fake_date"
        df = df.sort_values(time_col)
 
 

    # --- Aggregate & accumulate ---
    agg_df = (
        df.set_index(time_col)[value_col]
        .resample(freq)
        .mean()
        .dropna()
        .to_frame(name=value_col)
        .reset_index()
    )

    agg_df["accumulative_complexity"] = agg_df[value_col].cumsum()

    # --- Plot ---
    fig, ax = plt.subplots(figsize=(12, 6), dpi=150)
    ax.plot(
        agg_df[time_col],
        agg_df["accumulative_complexity"],
        color="steelblue",
        linewidth=2,
        marker="o",
        label="Accumulative Complexity"
    )

    ax.set_title(f"{title} ({'Weekly' if freq=='W' else 'Monthly'})")
    ax.set_xlabel("Time")
    ax.set_ylabel("Accumulative Complexity")
    ax.grid(alpha=0.8)
    ax.legend(loc="best")

    # --- Convert to base64 ---
    buf = io.BytesIO()
    fig.savefig(buf, format="png", bbox_inches="tight")
    plt.close(fig)
    buf.seek(0)
    return base64.b64encode(buf.read()).decode("ascii")


# ---- helpers ----
def detect_date_col(df):
    # 1) names that hint at date/time
    for c in df.columns:
        if any(k in c.lower() for k in ["date", "time", "timestamp", "created"]):
            return c
    # 2) try parsing any object column; keep the one with best success rate
    best_c, best_ratio = None, 0
    for c in df.select_dtypes(include=["object"]).columns:
        parsed = pd.to_datetime(df[c], errors="coerce")
        ratio = parsed.notna().mean()
        if ratio > best_ratio and ratio >= 0.7:
            best_c, best_ratio = c, ratio
    return best_c

def detect_value_col(df, exclude=None):
    exclude = set(exclude or [])
    # prefer columns with complexity-ish names
    for c in df.columns:
        if c in exclude:
            continue
        if ("complex" in c.lower() or "variation" in c.lower() or "delta" in c.lower()) \
            and pd.api.types.is_numeric_dtype(df[c]):
            return c
    # else first numeric that isn't obviously an id/index
    for c in df.columns:
        if c in exclude:
            continue
        if pd.api.types.is_numeric_dtype(df[c]) and not any(t in c.lower() for t in ["id","index","idx"]):
            return c
    return None


def plot_time_vs_complexity(
    df: pd.DataFrame,
    date_col: str,
    value_col: str,
    *,
    prefer_line: bool = True,   # set False to use bars
    freq: str,    # 'D' | 'W' | 'M' | None (no resample)
    title: str = "Corresponding Complexity Change over Time",
) -> tuple[str, str, str]:
    """
    Returns (b64_png, resolved_time_col, resolved_value_col).
    - Detects/validates value_col: tries numeric-friendly columns; uses your 70% rule
    - Detects/validates date_col: if parsing fails, uses index-based time axis
    - Optional resample for nicer ticks
    """
    df = df.copy()

    # --- Detect/confirm date col ---
    if date_col is None:
        # try obvious date/time-like columns first
        for c in df.columns:
            cl = str(c).lower()
            if any(k in cl for k in ["date", "time", "timestamp", "created", "dt"]):
                try:
                    parsed = pd.to_datetime(df[c], errors="raise")
                    df[c] = parsed
                    date_col = c
                    break
                except Exception:
                    pass
        if date_col is None:
            # try any column that parses reasonably well
            best, score = None, 0.0
            for c in df.columns:
                try:
                    p = pd.to_datetime(df[c], errors="coerce")
                    ok = p.notna().mean()
                    if ok > score and ok >= 0.7:
                        best, score = c, ok
                except Exception:
                    continue
            date_col = best

    # --- Detect/confirm value col (your 70% numeric rule) ---
    if value_col is None:
        for c in df.columns:
            if c == date_col:
                continue
            s = pd.to_numeric(df[c], errors="coerce")
            if s.notna().mean() > 0.7:
                df[c] = s
                value_col = c
                break
    if value_col is None:
        raise RuntimeError(
            "Could not find a numeric 'complexity' column. Columns: " + ", ".join(map(str, df.columns))
        )

    # --- Build a usable time axis ---
    if date_col is None:
        df["_time"] = np.arange(len(df))
        time_col = "_time"
    else:
        parsed = pd.to_datetime(df[date_col], errors="coerce")
        if parsed.notna().mean() < 0.7:
            df["_time"] = np.arange(len(df))
            time_col = "_time"
        else:
            df[date_col] = parsed
            time_col = date_col

    # --- Clean & sort ---
    vals = pd.to_numeric(df[value_col], errors="coerce")
    m = vals.replace([np.inf, -np.inf], np.nan).notna() & df[time_col].notna()
    plot_df = df.loc[m, [time_col, value_col]].sort_values(by=time_col).reset_index(drop=True)
    if plot_df.empty:
        raise ValueError("No valid rows to plot after cleaning.")

    # --- Optional resample for nicer timeline (only if time is datetime-like) ---
    if freq in {"D", "W", "M"} and np.issubdtype(plot_df[time_col].dtype, np.datetime64):
        plot_df = (
            plot_df.set_index(time_col)[value_col]
                   .resample(freq).mean()
                   .dropna()
                   .to_frame(name=value_col)
                   .reset_index()
        )

    # --- Plot ---
    fig, ax = plt.subplots(figsize=(12, 6), dpi=150)
    if prefer_line or not np.issubdtype(plot_df[time_col].dtype, np.datetime64):
        ax.plot(plot_df[time_col], plot_df[value_col], linewidth=1.8)
    else:
        ax.bar(plot_df[time_col], plot_df[value_col])

    ax.set_title(title)
    ax.set_ylabel("Complexity")
    ax.set_xlabel("Time")
    if np.issubdtype(plot_df[time_col].dtype, np.datetime64):
        fig.autofmt_xdate(rotation=15)
    else:
        # many points? reduce tick crowding
        n = len(plot_df)
        if n > 20:
            step = max(1, n // 12)
            ax.set_xticks(plot_df[time_col][::step])
    ax.grid(alpha=0.85)

    buf = io.BytesIO()
    fig.savefig(buf, format="png", bbox_inches="tight")
    plt.close(fig)
    buf.seek(0)
    b64 = base64.b64encode(buf.read()).decode("ascii")
    return b64, time_col, value_col


# extract segments
def extract_segments(splits):
    """
    å°†å¤šç§å½¢æ€çš„ segments å®¹å™¨ï¼Œç»Ÿä¸€è§£ææˆï¼š
    [{'start': int, 'end': int, 'AdjR2': float}, ...]
    å¯èƒ½çš„å½¢æ€åŒ…æ‹¬ï¼š
      - [dict, dict, ...]
      - ( [dict, dict, ...], [boundaries...] )
      - {'segments': [dict, ...]}
      - {0:{...},1:{...}}  # dict-of-dicts
    """
    # list/tuple
    if isinstance(splits, (list, tuple)):
        if len(splits) > 0 and isinstance(splits[0], dict):
            return list(splits)
        if len(splits) > 0 and isinstance(splits[0], (list, tuple)):
            cand = splits[0]
            if len(cand) > 0 and isinstance(cand[0], dict):
                return list(cand)
        if all(isinstance(s, dict) for s in splits):
            return list(splits)
    # dict
    if isinstance(splits, dict):
        if "segments" in splits and isinstance(splits["segments"], (list, tuple)):
            return list(splits["segments"])
        vals = list(splits.values())
        if vals and isinstance(vals[0], dict) and "start" in vals[0] and "end" in vals[0]:
            return vals
    raise ValueError("Cannot parse `segs` into a list of segment dicts.")


import matplotlib.dates as mdates

def plot_segments(df: pd.DataFrame, date_col: str, value_col: str):
    # -------- å‚æ•°ï¼šend æ˜¯å¦ä¸ºé—­åŒºé—´ï¼ˆé»˜è®¤ Falseï¼šå³å¼€åŒºé—´ï¼‰ --------
    END_IS_INCLUSIVE = False

    # æŠŠæ—¥æœŸåˆ—å˜æˆ datetime â†’ æ•°å€¼è½´ (seconds)
    dt = pd.to_datetime(df[date_col], errors="coerce")
    x_num = dt.view("int64") / 1e9  # ns â†’ seconds
    y_num = df[value_col].to_numpy(dtype=float)

    points = np.column_stack([x_num, y_num])

    segs, cuts = split_by_metric(
        points,
        drop_thre=0.001,
        w=1,
        min_len=8,
        rel_drop=True,
        rel_drop_thre=0.05,
        k=1,
        metric='mse'
    )

    seg_list = extract_segments(segs)


    # ---- ç”»å›¾ ----
    fig, ax = plt.subplots(figsize=(14, 8))

    # å…¨éƒ¨ envelope èƒŒæ™¯ç‚¹
    ax.scatter(
        df[date_col],
        df[value_col],
        s=3,
        color="red",
        edgecolors="black",
        linewidths=0.5,
        alpha=0.9,
        zorder=3,
        label="envelope points"
    )

    prev_end_x_num = None
    prev_end_y = None

    # æŒ‰åˆ†æ®µç”» piecewise OLS
    for i, seg in enumerate(seg_list, start=1):
        s = int(seg["start"])
        e = int(seg["end"])
        # å¦‚æœä½ é€»è¾‘é‡Œ end æ˜¯é—­åŒºé—´ï¼Œå¯ä»¥è¿™ä¹ˆè°ƒï¼š
        if END_IS_INCLUSIVE:
            e = e + 1

        g = df.iloc[s:e]
        if g.empty:
            continue



        # segment ç‚¹ï¼ˆç¨å¤§ä¸€ç‚¹ï¼Œä¾¿äºåˆ†æ®µè§‚å¯Ÿï¼‰
        ax.scatter(
            g[date_col],
            g[value_col],
            s=4,
            zorder=4,
            label=f"Seg {i}"
        )

        if len(g) >= 2:
            # 1) datetime â†’ matplotlib æ•°å€¼æ—¥æœŸ
            xd = mdates.date2num(g[date_col])
            yd = g[value_col].to_numpy()

            # 2) ä¸€é˜¶çº¿æ€§æ‹Ÿåˆ
            m, b = np.polyfit(xd, yd, 1)


            # 3) è¯¥æ®µçš„æ‹Ÿåˆçº¿ x èŒƒå›´
            xfit = np.linspace(xd.min(), xd.max(), 200)
            yfit = m * xfit + b

            # å½“å‰æ®µçš„â€œé¦–å°¾â€ç‚¹ï¼ˆæ•°å€¼åæ ‡ï¼‰
            seg_start_x_num = xfit[0]
            seg_start_y = yfit[0]
            seg_end_x_num = xfit[-1]
            seg_end_y = yfit[-1]

            # 4) ç”»è¯¥æ®µå›å½’çº¿
            ax.plot(
                mdates.num2date(xfit),
                yfit,
                linewidth=2,
                color="red",
                zorder=5
            )

            # 5) å’Œä¸Šä¸€æ®µâ€œé¦–å°¾ç›¸è¿â€
            if prev_end_x_num is not None:
                ax.plot(
                    [mdates.num2date(prev_end_x_num), mdates.num2date(seg_start_x_num)],
                    [prev_end_y, seg_start_y],
                    linewidth=2,
                    color="red",
                    zorder=5
                )

            # æ›´æ–°ä¸Šä¸€æ®µçš„æœ«å°¾ç‚¹
            prev_end_x_num = seg_end_x_num
            prev_end_y = seg_end_y

    ax.set_title("Envelope points with segments (piecewise OLS, end-to-start linked)")
    ax.set_xlabel("Time")
    ax.set_ylabel("Complexity")
    ax.legend(ncol=2)

    # --- Convert figure to base64 PNG ---
    buf = io.BytesIO()
    fig.savefig(buf, format="png", bbox_inches="tight")
    plt.close(fig)
    buf.seek(0)
    b64 = base64.b64encode(buf.read()).decode("ascii")

    return b64


def plot_weekly_change(
    df,
    date_col: str,
    value_col: str,
    agg="mean",
    title="Weekly Change in Complexity",
):
    """
    æŒ‰å‘¨èšåˆ upper envelopeï¼ˆy_envelopeï¼‰ï¼Œç”»å‡ºä¸€å¼ æ¯å‘¨å¤æ‚åº¦æ°´å¹³/å˜åŒ–çš„å›¾ã€‚

    Parameters
    ----------
    df : DataFrame
        å½¢å¦‚ [x_mid, y_envelope] çš„è¡¨ï¼ˆæˆ–æœ‰å…¶ä»–åˆ—ä¹Ÿå¯ä»¥ï¼‰ã€‚
    date_col : str
        æ—¶é—´åˆ—åï¼Œé»˜è®¤ "x_mid"ã€‚
    value_col : str
        å¤æ‚åº¦æ•°å€¼åˆ—åï¼Œé»˜è®¤ "y_envelope"ã€‚
    agg : {"mean", "sum", "median"}
        æ¯å‘¨èšåˆæ–¹å¼ï¼Œé»˜è®¤å– meanã€‚
    title : str
        å›¾è¡¨æ ‡é¢˜ã€‚

    Returns
    -------
    img_b64 : str or None
        base64 ç¼–ç åçš„ PNG å­—ç¬¦ä¸²ï¼›å¦‚æœæ•°æ®ä¸è¶³è¿”å› Noneã€‚
    """

    if df is None or len(df) == 0:
        return None

    # åªå–éœ€è¦çš„åˆ—
    data = df[[date_col, value_col]].copy()

    # ç¡®ä¿æ—¶é—´åˆ—æ˜¯ datetime
    data[date_col] = pd.to_datetime(data[date_col], errors="coerce")
    data = data.dropna(subset=[date_col, value_col])

    if data.empty:
        return None

    # æŒ‰æ—¶é—´æ’åºå¹¶è®¾ä¸ºç´¢å¼•
    data = data.sort_values(date_col).set_index(date_col)

    # === æŒ‰å‘¨èšåˆ ===
    if agg == "sum":
        weekly = data[value_col].resample("W").sum()
    elif agg == "median":
        weekly = data[value_col].resample("W").median()
    else:  # é»˜è®¤ mean
        weekly = data[value_col].resample("W").mean()

    if weekly.empty:
        return None

    # å¦‚æœä½ æ›´æƒ³çœ‹â€œå˜åŒ–é‡â€ï¼Œå¯ä»¥æ”¹æˆï¼š
    # weekly_change = weekly.diff()
    # ç„¶åä¸‹é¢æŠŠ weekly æ¢æˆ weekly_change
    # è¿™é‡Œå…ˆç”»æ¯å‘¨çš„å¹³å‡æ°´å¹³

    # === ç”»å›¾ ===
    fig, ax = plt.subplots(figsize=(8, 3))

    ax.bar(weekly.index, weekly.values, width=5)  # ç®€å•æŸ±çŠ¶å›¾

    ax.set_title(title)
    ax.set_xlabel("Week")
    ax.set_ylabel(f"Weekly {agg} of {value_col}")

    fig.autofmt_xdate(rotation=30)
    plt.tight_layout()

    buf = io.BytesIO()
    fig.savefig(buf, format="png", bbox_inches="tight")
    buf.seek(0)
    img_b64 = base64.b64encode(buf.read()).decode("ascii")

    plt.close(fig)
    buf.close()

    return img_b64


# Todo 
# def plot_temporal_variation_change(
#     df,
#     date_col="x_mid",
#     value_col="y_envelope",
#     freq="W",
#     title="Temporal Variation in Complexity (Î” Change)"
# ):
#     """ Show red if complexity increases, green if decreases """
#     if df is None or len(df)==0:
#         return None

#     data = df[[date_col, value_col]].copy().reset_index(drop=True)

#     data[date_col] = pd.to_datetime(data[date_col], errors="coerce")
#     data = data.dropna(subset=[date_col, value_col])
    
#     data = data.sort_values(date_col)

#     # ğŸ”¥ Weekly mean â€” å¯æ”¹ median/sum
#     weekly = data.set_index(date_col)[value_col].resample(freq).mean()
#     weekly = weekly.dropna() 

#     change = weekly.diff()  # --> å·®åˆ†æ›²çº¿ Î”y

#     if change.empty or change.isna().all():
#         return None

#     # ğŸ¨ çº¢=ä¸Šå‡ï¼ˆå˜å¤æ‚ï¼‰ï¼Œç»¿=ä¸‹é™ï¼ˆå˜ç®€å•ï¼‰
#     colors = ["red" if x > 0 else "green" for x in change]

#     # === ç»˜å›¾ ===
#     fig, ax = plt.subplots(figsize=(16,8))

#     ax.bar(change.index, change.values, color=colors, width=6)

#     ax.axhline(0, color="black", linewidth=1.2)   # åŸºå‡†çº¿
#     ax.set_title(title)
#     ax.set_ylabel("Î” Complexity (week over week)")
#     ax.set_xlabel("Time (Weekly)")
#     fig.autofmt_xdate(rotation=25)
#     plt.tight_layout()

#     buf = io.BytesIO()
#     fig.savefig(buf, format="png", bbox_inches="tight")
#     buf.seek(0)
#     img_b64 = base64.b64encode(buf.read()).decode("ascii")

#     plt.close(fig)
#     buf.close()
#     return img_b64
def plot_temporal_variation_change(
    df,
    date_col="x_mid",
    value_col="y_envelope",
    freq="W",
    title="Tech Debt Over Time",
    window=None,   # "3M","6M","1Y","3Y","5Y"... æˆ– None
):
    """
    å·¦è½´ï¼šå¤æ‚åº¦å˜åŒ–é‡ |Î”|ï¼ˆçº¢=å˜å¤æ‚ï¼Œç»¿=å˜ç®€å•ï¼Œæ‰€æœ‰æŸ±å­å‘ä¸Šï¼Œä¸”è§†è§‰æ›´å¤§ï¼‰
    å³è½´ï¼šå¤æ‚åº¦æ°´å¹³ï¼ˆweekly meanï¼‰æŠ˜çº¿
    window:
        None  -> å…¨éƒ¨å†å²
        "3M"  -> è¿‡å» 3 ä¸ªæœˆ
        "6M"  -> è¿‡å» 6 ä¸ªæœˆ
        "1Y"  -> è¿‡å» 1 å¹´
        "3Y"  -> è¿‡å» 3 å¹´
        "5Y"  -> è¿‡å» 5 å¹´
        ä»¥åŠä»»æ„ç±»ä¼¼æ ¼å¼çš„ "æ•°å­—+M/Y"
    """
    if df is None or len(df) == 0:
        return None

    data = df[[date_col, value_col]].copy().reset_index(drop=True)

    # --- æ¸…æ´— & æ’åº ---
    data[date_col] = pd.to_datetime(data[date_col], errors="coerce")
    data = data.dropna(subset=[date_col, value_col])
    data = data.sort_values(date_col)

    # ğŸ”¥ æŒ‰å‘¨èšåˆå¾—åˆ°â€œå¤æ‚åº¦æ°´å¹³â€ï¼ˆå…¨é‡ï¼‰
    weekly_full = (
        data.set_index(date_col)[value_col]
        .resample(freq)
        .mean()
        .dropna()
    )
    if weekly_full.empty or len(weekly_full) < 2:
        return None

    # ===== é€šç”¨ window è§£æé€»è¾‘ =====
    weekly = weekly_full
    if window:
        w = str(window).strip().upper()  # ä¾‹å¦‚ "3Y" / "5Y" / "6M"
        last_date = weekly_full.index.max()
        cutoff = None

        try:
            if w.endswith("M"):
                n_months = int(w[:-1])
                cutoff = last_date - pd.DateOffset(months=n_months)
            elif w.endswith("Y"):
                n_years = int(w[:-1])
                cutoff = last_date - pd.DateOffset(years=n_years)
        except ValueError:
            cutoff = None  # è§£æå¤±è´¥å°±å½“æ²¡å¡« window

        if cutoff is not None:
            weekly_window = weekly_full[weekly_full.index >= cutoff]
            # å¦‚æœæ•°æ®å¤ªå°‘ï¼ˆæ¯”å¦‚ä¸è¶³ 5 å‘¨ï¼‰ï¼Œå°±è‡ªåŠ¨ fallback å›å…¨é‡
            if len(weekly_window) >= 5:
                weekly = weekly_window
            else:
                weekly = weekly_full  # å›é€€åˆ° ALL

    # Î” complexityï¼ˆå‘¨å¯¹å‘¨å˜åŒ–ï¼‰
    change = weekly.diff().dropna()
    if change.empty:
        return None

    # é«˜åº¦ç”¨ç»å¯¹å€¼ï¼Œé¢œè‰²ç”¨æ­£è´Ÿ
    abs_change = change.abs()
    colors = ["red" if x > 0 else "green" for x in change.values]

    abs_vals = abs_change.values

    # ====== ç”¨åˆ†ä½æ•°æ§åˆ¶ y è½´ä¸Šé™ï¼Œè®©å¤§éƒ¨åˆ†æŸ±å­ã€Œé•¿é«˜ã€ ======
    cap = np.percentile(abs_vals, 98)
    cap = max(cap, np.max(abs_vals) * 0.25, 1e-6)

    # çœŸæ­£ç”»å‡ºæ¥çš„é«˜åº¦ï¼ˆè¶…è¿‡ cap çš„ç›´æ¥æˆªæ–­åˆ° capï¼‰
    bar_heights = np.minimum(abs_vals, cap)

    # ========= ç»˜å›¾éƒ¨åˆ† =========
    fig, ax = plt.subplots(figsize=(36, 16))

    # --- å·¦è½´ï¼šå˜åŒ–é‡æŸ±å­ï¼ˆå…¨éƒ¨å‘ä¸Šï¼Œæ”¾å¤§+åŠ ç²—ï¼‰---
    ax.bar(
        change.index,
        bar_heights,
        color=colors,
        width=10,
        alpha=0.9,
        label="|Î” Tech Debt| (Week over Week)",
    )

    ax.axhline(0, color="black", linewidth=1, alpha=0.7)
    ax.set_facecolor("#FFFFFF")
    ax.grid(axis="y", linestyle="--", alpha=0.25)

    ax.spines["top"].set_visible(False)
    ax.spines["right"].set_visible(False)

    y_lim = cap * 1.15
    ax.set_ylim(0, y_lim)
    ax.set_ylabel("|Î” Complexity| (Weekly Change)")

    # --- å¯¹äºè¶…è¿‡ cap çš„æç«¯å€¼ï¼Œå•ç‹¬ç”¨ç«–çº¿ + æ ‡æ³¨è¡¨ç¤º ---
    outlier_mask = abs_vals > cap
    if outlier_mask.any():
        for x, real_y, sign in zip(
            change.index[outlier_mask],
            change.values[outlier_mask],
            np.sign(change.values[outlier_mask]),
        ):
            ax.vlines(
                x,
                0,
                y_lim,  # æ‹‰åˆ°é¡¶
                color="green" if sign < 0 else "red",
                linewidth=2.0,
                alpha=0.9,
            )
            ax.annotate(
                f"{real_y:.0f}",
                xy=(x, y_lim),
                xytext=(0, 6),
                textcoords="offset points",
                ha="center",
                va="bottom",
                fontsize=8,
                alpha=0.8,
            )

    # --- å³è½´ï¼šå¤æ‚åº¦æ°´å¹³æŠ˜çº¿ ---
    ax2 = ax.twinx()

    aligned_weekly = weekly.loc[change.index]
    ax2.plot(
        aligned_weekly.index,
        aligned_weekly.values,
        color="#1f77b4",
        linewidth=1.4,
        marker="o",
        markersize=3.0,
        markerfacecolor="white",
        markeredgewidth=0.8,
        alpha=0.92,
        label="Weekly Complexity Level",
    )
    ax2.set_ylabel("Weekly Complexity Level")
    ax2.set_ylim(0, aligned_weekly.max() * 1.25)

    # --- æ—¶é—´è½´æ ¼å¼ ---
    ax.xaxis.set_major_locator(mdates.YearLocator())
    ax.xaxis.set_major_formatter(mdates.DateFormatter("%Y"))
    plt.setp(ax.get_xticklabels(), rotation=25, ha="right")

    # --- åˆå¹¶å›¾ä¾‹ ---
    handles1, labels1 = ax.get_legend_handles_labels()
    handles2, labels2 = ax2.get_legend_handles_labels()
    ax.legend(handles1 + handles2, labels1 + labels2, loc="upper left")

    # æ ‡é¢˜ & è½´æ ‡ç­¾
    if window:
        ax.set_title(f"{title} Â· Range: {window}", fontsize=14, fontweight="bold")
    else:
        ax.set_title(title, fontsize=14, fontweight="bold")

    ax.set_xlabel("Time (Weekly)")

    plt.tight_layout()

    # ========= è¾“å‡ºä¸º base64 =========
    buf = io.BytesIO()
    fig.savefig(buf, format="png", bbox_inches="tight", dpi=150)
    buf.seek(0)
    img_b64 = base64.b64encode(buf.read()).decode("ascii")

    plt.close(fig)
    buf.close()
    return img_b64



def plot_accumulative_complexity_multi(
    series_dict,
    date_col: str = "x_mid",
    value_col: str = "y_envelope",
    title: str = "Project Comparison â€“ Accumulative Complexity",
    freq: str = "W",
):
    """
    series_dict: { label -> highlight_df }ï¼Œæ¯ä¸ª df è‡³å°‘åŒ…å« [date_col, value_col]
    ç”¨äºå¤šä¸ªé¡¹ç›®çš„ç´¯ç§¯å¤æ‚åº¦å¯¹æ¯”ã€‚
    """
    if not series_dict:
        return None

    fig, ax = plt.subplots(figsize=(12, 8), dpi=150)

    for label, df in series_dict.items():
        if df is None or df.empty:
            continue

        local = df[[date_col, value_col]].dropna().copy()
        local[date_col] = pd.to_datetime(local[date_col], errors="coerce")
        local = local.dropna(subset=[date_col, value_col]).sort_values(date_col)

        if local.empty:
            continue

        agg = (
            local.set_index(date_col)[value_col]
            .resample(freq)
            .mean()
            .dropna()
            .to_frame()
            .reset_index()
        )
        if agg.empty:
            continue

        agg["accumulative_complexity"] = agg[value_col].cumsum()

        ax.plot(
            agg[date_col],
            agg["accumulative_complexity"],
            linewidth=2,
            marker="o",
            label=str(label),
        )

    if not ax.lines:
        plt.close(fig)
        return None

    ax.set_title(title)
    ax.set_xlabel("Time")
    ax.set_ylabel("Accumulative Complexity")
    ax.grid(alpha=0.6)
    ax.legend(title="Project", fontsize=9)

    buf = io.BytesIO()
    fig.savefig(buf, format="png", bbox_inches="tight")
    plt.close(fig)
    buf.seek(0)
    return base64.b64encode(buf.read()).decode("ascii")


def _prepare_time_series(df, date_col="x_mid", value_col="y_envelope"):
    """æ¸…ç† + æŒ‰æ—¶é—´æ’åºçš„å·¥å…·å‡½æ•°"""
    local = df[[date_col, value_col]].dropna().copy()
    local[date_col] = pd.to_datetime(local[date_col], errors="coerce")
    local = local.dropna(subset=[date_col, value_col]).sort_values(date_col)
    return local
def plot_envelope_multi(
    series_dict,
    date_col: str = "x_mid",
    value_col: str = "y_envelope",
    title: str = "Project Comparison â€“ Complexity Envelope Segments",
    normalize: bool = False,
    align_start: bool = False,
):
    if not series_dict:
        return None

    fig, ax = plt.subplots(figsize=(12, 8), dpi=220)  # ğŸ”¥ æ›´å¤§ + æ›´æ¸…æ™°
    # fig.subplots_adjust(left=0.06, right=0.97, top=0.92, bottom=0.09)  # ğŸ”¥ å»ç™½è¾¹ï¼Œæ”¾å¤§ç”»é¢


    for label, df in series_dict.items():
        local = _prepare_time_series(df, date_col, value_col)
        if local.empty:
            continue

        y = local[value_col].astype(float)

        if normalize:
            ymin, ymax = y.min(), y.max()
            if np.isclose(ymax, ymin):
                y_plot = np.zeros_like(y, dtype=float)
            else:
                y_plot = (y - ymin) / (ymax - ymin)
        else:
            y_plot = y

        if align_start:
            x = np.arange(len(local))
        else:
            x = local[date_col]

        ax.plot(
            x,
            y_plot,
            linewidth=1.8,
            marker="o",
            label=str(label),
        )

    if not ax.lines:
        plt.close(fig)
        return None

    if normalize:
        ax.set_ylabel("Normalized Envelope Complexity (0â€“1)")
    else:
        ax.set_ylabel("Envelope Complexity")

    if align_start:
        ax.set_xlabel("Steps since project start")
        ax.set_title(title + " â€” Aligned at Start" + ( " [Normalized]" if normalize else "" ))
    else:
        ax.set_xlabel("Time")
        ax.set_title(title)

    ax.grid(alpha=0.6)
    ax.legend(title="Project", fontsize=9)

    buf = io.BytesIO()
    fig.savefig(buf, format="png", bbox_inches="tight")
    plt.close(fig)
    buf.seek(0)
    return base64.b64encode(buf.read()).decode("ascii")


def plot_timeline_multi(
    series_dict,
    date_col: str = "x_mid",
    value_col: str = "y_envelope",
    title: str = "Project Comparison â€“ Complexity Timeline",
    freq: str = "W",
    normalize: bool = False,
    align_start: bool = False,   # â† æ–°å¢
):
    if not series_dict:
        return None

    fig, ax = plt.subplots(figsize=(12, 8), dpi=220)  # ğŸ”¥ æ›´å¤§ + æ›´æ¸…æ™°
    # fig.subplots_adjust(left=0.06, right=0.97, top=0.92, bottom=0.09)  # ğŸ”¥ å»ç™½è¾¹ï¼Œæ”¾å¤§ç”»é¢


    for label, df in series_dict.items():
        local = _prepare_time_series(df, date_col, value_col)
        if local.empty:
            continue

        ts = (
            local.set_index(date_col)[value_col]
            .resample(freq)
            .mean()
            .dropna()
            .to_frame()
            .reset_index()
        )
        if ts.empty:
            continue

        y = ts[value_col].astype(float)

        # normalize
        if normalize:
            ymin, ymax = y.min(), y.max()
            if np.isclose(ymax, ymin):
                y_plot = np.zeros_like(y, dtype=float)
            else:
                y_plot = (y - ymin) / (ymax - ymin)
        else:
            y_plot = y

        # ğŸ”¥ å¯¹é½èµ·ç‚¹ï¼šX æ”¹ä¸º 0,1,2,...
        if align_start:
            x = np.arange(len(ts))
        else:
            x = ts[date_col]

        ax.plot(
            x,
            y_plot,
            linewidth=1.8,
            marker="o",
            label=str(label),
        )

    if not ax.lines:
        plt.close(fig)
        return None

    if normalize:
        ax.set_ylabel("Normalized Complexity (0â€“1)")
    else:
        ax.set_ylabel("Average Complexity")

    if align_start:
        ax.set_xlabel(f"Periods since project start ({freq})")
        ax.set_title(title + " â€” Aligned at Start" + ( " [Normalized]" if normalize else "" ))
    else:
        ax.set_xlabel("Time")
        ax.set_title(title + f" ({freq})")

    ax.grid(alpha=0.6)
    ax.legend(title="Project", fontsize=9)

    buf = io.BytesIO()
    fig.savefig(buf, format="png", bbox_inches="tight")
    plt.close(fig)
    buf.seek(0)
    return base64.b64encode(buf.read()).decode("ascii")

def plot_accumulative_complexity_multi(
    series_dict,
    date_col: str = "x_mid",
    value_col: str = "y_envelope",
    title: str = "Project Comparison â€“ Accumulative Complexity",
    freq: str = "W",
    normalize: bool = False,
    align_start: bool = False,
):
    if not series_dict:
        return None

    fig, ax = plt.subplots(figsize=(12, 8), dpi=220)  # ğŸ”¥ æ›´å¤§ + æ›´æ¸…æ™°
    # fig.subplots_adjust(left=0.06, right=0.97, top=0.92, bottom=0.09)  # ğŸ”¥ å»ç™½è¾¹ï¼Œæ”¾å¤§ç”»é¢


    for label, df in series_dict.items():
        local = _prepare_time_series(df, date_col, value_col)
        if local.empty:
            continue

        agg = (
            local.set_index(date_col)[value_col]
            .resample(freq)
            .mean()
            .dropna()
            .to_frame()
            .reset_index()
        )
        if agg.empty:
            continue

        agg["accumulative_complexity"] = agg[value_col].cumsum()
        y = agg["accumulative_complexity"].astype(float)

        if normalize:
            ymin, ymax = float(y.min()), float(y.max())
            if np.isclose(ymax, ymin):
                y_plot = np.zeros_like(y, dtype=float)
            else:
                y_plot = (y - ymin) / (ymax - ymin)
        else:
            y_plot = y

        # ğŸ”¥ X æŒ‰èµ·ç‚¹å¯¹é½ / ä½¿ç”¨çœŸå®æ—¶é—´
        if align_start:
            x = np.arange(len(agg))
        else:
            x = agg[date_col]

        ax.plot(
            x,
            y_plot,
            linewidth=2,
            marker="o",
            label=str(label),
        )

    if not ax.lines:
        plt.close(fig)
        return None

    if normalize:
        ax.set_ylabel("Normalized Accumulative Complexity (0â€“1)")
    else:
        ax.set_ylabel("Accumulative Complexity")

    if align_start:
        ax.set_xlabel(f"Periods since project start ({freq})")
        ax.set_title(title + " â€” Aligned at Start" + ( " [Normalized]" if normalize else "" ))
    else:
        ax.set_xlabel("Time")
        ax.set_title(title + f" ({freq})")

    ax.grid(alpha=0.6)
    ax.legend(title="Project", fontsize=9)

    buf = io.BytesIO()
    fig.savefig(buf, format="png", bbox_inches="tight")
    plt.close(fig)
    buf.seek(0)
    return base64.b64encode(buf.read()).decode("ascii")

def plot_temporal_variation_multi(
    series_dict,
    date_col: str = "x_mid",
    value_col: str = "y_envelope",
    title: str = "Project Comparison â€“ Temporal Variation in Complexity",
    freq: str = "W",
    normalize: bool = False,
    align_start: bool = False,
):
    if not series_dict:
        return None

    fig, ax = plt.subplots(figsize=(12, 8), dpi=150)

    for label, df in series_dict.items():
        local = _prepare_time_series(df, date_col, value_col)
        if local.empty:
            continue

        weekly = (
            local.set_index(date_col)[value_col]
            .resample(freq)
            .mean()
            .dropna()
        )
        change = weekly.diff().dropna()
        if change.empty:
            continue

        y = change.values.astype(float)

        if normalize:
            ymin, ymax = y.min(), y.max()
            if np.isclose(ymax, ymin):
                y_norm = np.zeros_like(y, dtype=float)
            else:
                # æ ‡å‡†åŒ–åˆ° [-1,1] åŒºé—´
                denom = max(abs(ymax), abs(ymin))
                y_norm = y / denom
            y_plot = y_norm
        else:
            y_plot = y

        # ğŸ”¥ X å¯¹é½
        if align_start:
            x = np.arange(len(change))
        else:
            x = change.index

        ax.plot(
            x,
            y_plot,
            linewidth=1.8,
            marker="o",
            label=str(label),
        )

    if not ax.lines:
        plt.close(fig)
        return None

    if normalize:
        ax.set_ylabel("Normalized Î” Complexity (âˆ’1 ~ +1)")
    else:
        ax.set_ylabel("Î” Complexity")

    if align_start:
        ax.set_xlabel(f"Periods since project start ({freq})")
        ax.set_title(title + " â€” Aligned at Start" + ( " [Normalized]" if normalize else "" ))
    else:
        ax.set_xlabel("Time")
        ax.set_title(title + f" ({freq} Î”)")

    ax.axhline(0, color="black", linewidth=1.0)
    ax.grid(alpha=0.6)
    ax.legend(title="Project", fontsize=9)

    buf = io.BytesIO()
    fig.savefig(buf, format="png", bbox_inches="tight")
    plt.close(fig)
    buf.seek(0)
    return base64.b64encode(buf.read()).decode("ascii")



def plot_raw_complexity(
    df,
    date_col: str = "Datetime",
    value_col: str = "complexity_raw",
    title: str = "Raw Complexity over Time",
):
    """
    ç›´æ¥ç”»åŸå§‹æ•°æ®ï¼šDatetime vs complexity_raw
    ä¸åš resampleï¼Œé€‚åˆä½œä¸ºæ•°æ®æ ·æœ¬å±•ç¤ºã€‚
    """
    if df is None or df.empty:
        return None

    data = df[[date_col, value_col]].copy()
    data[date_col] = pd.to_datetime(data[date_col], errors="coerce")
    data[value_col] = pd.to_numeric(data[value_col], errors="coerce")
    data = data.dropna(subset=[date_col, value_col]).sort_values(date_col)

    if data.empty:
        return None

    fig, ax = plt.subplots(figsize=(12, 4), dpi=150)

    # ç”¨ç»†çº¿ + å°ç‚¹è¡¨ç° raw data
    ax.plot(
        data[date_col],
        data[value_col],
        linewidth=0.8,
        marker=".",
        markersize=2,
    )

    ax.set_title(title)
    ax.set_xlabel("Time (raw commit timeline)")
    ax.set_ylabel("Raw Complexity")
    ax.grid(alpha=0.4)

    buf = io.BytesIO()
    fig.savefig(buf, format="png", bbox_inches="tight")
    plt.close(fig)
    buf.seek(0)
    return base64.b64encode(buf.read()).decode("ascii")